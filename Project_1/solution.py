# -*- coding: utf-8 -*-
"""PAI_assignment1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1l2r3P49bUqI8dz5mNLSa0eOCnPA9t6p7
"""

"""mounting google drive --> instructions:
place your files onto your google drive folder of your choice, then run this cell
you will be prompted to allow access to google colab
now select the file path on the server, the file directory can be found on the left vertical
taskbar. You can just navigate to the folder, right click and copy the directory of your .csv file"""

# from google.colab import drive
# drive.mount('/content/drive')

import numpy as np
import scipy

from sklearn.linear_model import Ridge

from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import RBF, DotProduct, WhiteKernel
from sklearn.kernel_approximation import Nystroem

#import matplotlib as plt

THRESHOLD = 0.5
W1 = 1
W2 = 20
W3 = 100
W4 = 0.01

def cost_function(true, predicted):
    """
        true: true values in 1D numpy array
        predicted: predicted values in 1D numpy array

        return: float
    """
    cost = (true - predicted) ** 2

    # true above threshold (case 1)
    mask = true > THRESHOLD
    mask_w1 = np.logical_and(predicted > true, mask)
    mask_w2 = np.logical_and(np.logical_and(predicted < true, predicted > THRESHOLD), mask)
    mask_w3 = np.logical_and(predicted < THRESHOLD, mask)

    cost[mask_w1] = cost[mask_w1] * W1
    cost[mask_w2] = cost[mask_w2] * W2
    cost[mask_w3] = cost[mask_w3] * W3

    # true value below threshold (case 2)
    mask = true <= THRESHOLD
    mask_w1 = np.logical_and(predicted > true, mask)
    mask_w2 = np.logical_and(predicted <= true, mask)

    cost[mask_w1] = cost[mask_w1] * W1
    cost[mask_w2] = cost[mask_w2] * W2

    # reward for correctly identified safe regions
    reward = W4 * np.logical_and(predicted < THRESHOLD, true < THRESHOLD)

    if reward is None:
        reward = 0
    return np.mean(cost) - np.mean(reward)

"""Fill in the methods of the Model. Please do not change the given methods for the checker script to work.
You can add new methods, and make changes. The checker script performs:

    M = Model()
    M.fit_model(train_x,train_y)
    prediction = M.predict(test_x)

It uses predictions to compare to the ground truth using the cost_function above.
"""

class Model():

    def __init__(self):
        """
            TODO: enter your code here
        """
        self.lamda = 1
        self.kernel = RBF() + WhiteKernel()
        self.model = GaussianProcessRegressor(kernel=self.kernel, n_restarts_optimizer=0,random_state=0)

    def predict(self, test_x):
        """
            TODO: enter your code here
        """
        y = self.model.predict(test_x)
        return y

    def fit_model(self, train_x, train_y):
        """
             TODO: enter your code here
        """
        data_xy = np.column_stack((train_x,train_y))
        rng = np.random.default_rng()
        approx = 'Random'

        # Nyostream approximation (not implemented yet)
        if(approx == 'Nystroem'):
            feature_map_nystroem = Nystroem(kernel='rbf',gamma=.2,random_state=1,n_components=300)
            data_transformed = feature_map_nystroem.fit_transform(train_x)

        # Select random samples from dataset
        if(approx == 'Random'):
            n = 6000
            data_transformed = rng.choice(data_xy,size=n, axis=0, replace=False)

        
        # Clusterize data into 
        if(approx == 'Clusters'):
            n_clusters = 20
            dist_thresehold = 0.07
            cluster_centers = rng.choice(data_xy,size=n_clusters, axis=0, replace=False)
            data_transformed = np.zeros((1,3))
            for i in range(n_clusters):
                cluster_center = cluster_centers[i,0:3]
                for point in data_xy:
                    dist = np.linalg.norm(cluster_center-point)
                    if(dist < dist_thresehold):
                        point_app = np.reshape(point,(1,3))
                        if(data_transformed.all()==0):
                            data_transformed = point_app
                            continue

                        data_transformed = np.append(data_transformed,point_app,axis=0)

        
        data_transformed_x = data_transformed[:,0:2]
        data_transformed_y = data_transformed[:,2]        
        
        self.data_x = data_transformed_x
        self.data_y = data_transformed_y

        self.model.fit(data_transformed_x[0:2,0:2], data_transformed_y[0:2])

        self.model.kernel.theta = self.optimizer()



        pass

    def obj_func(self,hyperparams)->float:

        self.model.kernel_.theta = hyperparams
        prediction = self.model.predict(self.data_x)
        cost = cost_function(self.data_y,prediction)
        self.model.kernel.theta = hyperparams
        return cost

    
    def optimizer(self):
        # * 'obj_func' is the objective function to be minimized, which
        #   takes the hyperparameters theta as parameter and an
        #   optional flag eval_gradient, which determines if the
        #   gradient is returned additionally to the function value
        # * 'initial_theta': the initial value for theta, which can be
        #   used by local optimizers
        # * 'bounds': the bounds on the values of theta
        #....
        # Returned are the best found hyperparameters theta and
        # the corresponding value of the target function.

        initial_theta = self.model.kernel_.theta
        optimalResult = scipy.optimize.minimize(self.obj_func, initial_theta, method='TNC')
        theta_opt = optimalResult.x
        final_cost = optimalResult.fun
        print(final_cost, '\n')
        return theta_opt


def main():
    train_x_name = "train_x.csv"
    train_y_name = "train_y.csv"

    # google drive directories for work in google colab - comment if working in .py file and uncomment original paths
    # train_x_name = "/content/drive/My Drive/ETHZ/ProbabilisticAI/Projects/Project1/train_x.csv"
    # train_y_name = "/content/drive/My Drive/ETHZ/ProbabilisticAI/Projects/Project1/train_y.csv"
    # test_x_name = "/content/drive/My Drive/ETHZ/ProbabilisticAI/Projects/Project1/test_x.csv"

    train_x = np.loadtxt(train_x_name, delimiter=',')
    train_y = np.loadtxt(train_y_name, delimiter=',')

    # load the test dateset
    test_x_name = "test_x.csv"
    test_x = np.loadtxt(test_x_name, delimiter=',')


    M = Model()
    M.fit_model(train_x, train_y)

if __name__ == "__main__":
    main()
    print("Completed sucessfully")

